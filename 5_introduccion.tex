\section{Introducción}
Los modelos son representaciones matemáticas de mecanismos que rigen fenómenos naturales que no se reconocen, controlan o comprenden plenamente, y el proceso de modelación abarca varios pasos que comienzan con una declaración clara de los objetivos del modelo, supuestos sobre sus límites del modelo, la adecuación de los datos disponibles, el diseño de la estructura del modelo, la evaluación de las simulaciones y la aportación de la información para los procesos de recomendación y rediseño (Tedeschi, 2006).
\vspace{.5cm}
 
La validación de un modelo en predicción del sistema es la comparación por medio de algún método de las predicciones del modelo con los valores observados del sistema real para determinar su capacidad predictiva; en esta etapa del proceso de modelación matemática se evalúan la exactitud y precisión del modelo, la primera se refiere a la proximidad de las predicciones $( z )$ con los valores observados $( y )$, por ejemplo, sus diferencias $ ( d=y-z ) $ del cero y la segunda a la dispersión de los puntos $ (z, y) $; sin embargo, en presencia de exactitud la precisión se mide cuantificando la dispersión de dichos puntos respecto a una referencia, por ejemplo, la recta determinista $ y=x $, o bien, evaluar la varianza de las diferencias $ (\sigma_{D}^{2}) $ alrededor del cero $ (\mu_{D}=0) $ (Medina-Peralta et al., 2017).
\vspace{.5cm}
 
En la literatura se han expuesto diferentes enfoques y técnicas para validar modelos. Las técnicas de validación se pueden agrupar en cuatro categorías principales: evaluación subjetiva (involucra a un número de expertos en el campo de interés), técnicas visuales (gráficas comparativas), medidas de desviación (basadas en las diferencias entre valores observados y simulados) y pruebas de estadísticas (Mayer y Butler, 1993).
\vspace{.5cm}
 
Entre las técnicas inferenciales, una de las más utilizadas es la Regresión Lineal (RL) entre los observados del sistema real $ (y) $ en función de los predichos del modelo a evaluar $ (z) $, $ y_{i} = \beta_{0} + \beta_{1}z_{i} +\epsilon $  donde $ \epsilon_{i} \sim NI(0,\sigma^{2}) $ ; la exactitud se evalúa por medio de una $ F $ conjunta verificando si simultáneamente $ \beta_{0} $ y $ \beta_{1} $ son cero y uno respectivamente (Yang et al., 2004; Tedeschi, 2006; Montgomery et al., 2012); y la precisión se evalúa por medio del coeficiente de determinación $ R^{2} $ (Balam, 2012), mientras más cerca esté de uno el modelo es más preciso.
Adicionalmente, Zacarias (2023) desarrolló un método no paramétrico para evaluar la exactitud de un modelo con la técnica de regresión lineal cuando no se cumplen los supuestos de normalidad y/o varianza constante, basada en la construcción de una región de confianza Bootstrap para el vector de parámetros de regresión. De modo que si el vector  $ (\beta_{0},\beta_{1})=(0,1) $ está contenido en dicha región de confianza, se concluye el modelo es exacto en predicción del sistema. En Zacarias (2023), para garantizar que las estimaciones sean confiables y resistentes a las influencias de datos atípicos se utilizaron estimadores de regresión robustos y se implementó el Wild Bootstrap robusto propuesto en Rana et al. (2012) bajo tres esquemas de remuestreo propuestos por (Wu, 1986) y dos propuestos por (Liu, 1988).
\vspace{.5cm}

Febles (2014) propuso un método para simular modelos que implica la creación de una muestra pareada de valores observados y predichos $ (z_{i},y_{i}) $ basada en la media $ (\bar{z}) $ y los parámetros $ (\beta_{0}, \beta_{1}, R^{2}, SCE) $ de un modelo de regresión entre los observados y predichos. Este método simula modelos de cuatro tipos (exacto-preciso, exacto-impreciso, inexacto-preciso, inexacto-impreciso) y considera cuatro casos de supuestos (normalidad-varianza constante, no normalidad-varianza constante, normalidad-varianza no constante, no normalidad-varianza no constante) en función de la normalidad y la varianza en el modelo de regresión. En Zacarías (2023), se mejoraron los simuladores de Febles (2014) al seleccionar valores plausibles de $ SCE $ que generan modelos exacto-precisos independientemente del supuesto cumplido. Además, se determinó una constante para el ancho de una banda horizontal donde se distribuyen los valores predichos y residuales. Se reemplazó el estadístico de Kolmogorov-Smirnov por el de Lilliefors para las pruebas de normalidad, y se implementó la prueba de Breusch-Pagan cuando los residuales cumplen el supuesto de normalidad y la de White cuando los residuales no se ajustan a la distribución normal.
\vspace{.5cm}

Balam (2012), para medir la precisión de un modelo con regresión lineal, propone la construcción de un intervalo de confianza Bootstrap de residuales balanceado con sesgo corregido acelerado BCa, para los casos cuando se cumple el supuesto de varianza constante, independiente si se cumple o no el supuesto de normalidad; y para los casos cuando no se cumple el supuesto de varianza constante, independientemente si se cumple o no el de normalidad, se construye un intervalo de confianza Bootstrap pareado balanceado método percentil con sesgo corregido acelerado BCa.
\vspace{.5cm}

Para medir la precisión se puede considerar el Wild Bootstrap robusto propuesto en Rana et al. (2012) ya que este considera la utilización de estimadores robustos y otros esquemas de remuestreo diferente al Bootstrap simple.
En el presente trabajo se implementará una propuesta a través de intervalos de confianza para evaluar la precisión de un modelo con la técnica de regresión lineal, basada en estimadores robustos y los esquemas de remuestreo Bootstrap propuestos por Rana et al. (2012) e implementados en Zacarías (2023). Se realizará un estudio de simulación para evaluar la eficacia de esta propuesta y se implementará en el lenguaje R (R Core Team, 2024).
